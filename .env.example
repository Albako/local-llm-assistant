# Lista modeli Ollama do pobrania (oddzielane przecinkami)
OLLAMA_MODELS=llama3.2:3b,llama3.2:1b,deepseek-r1:7b

# Ollama URL for the backend to connect
# The path '/ollama' will be redirected to the specified backend URL
OLLAMA_BASE_URL='http://localhost:11434'

OPENAI_API_BASE_URL=''
OPENAI_API_KEY=''

# AUTOMATIC1111_BASE_URL="http://localhost:7860"

# For production, you should only need one host as
# fastapi serves the svelte-kit built frontend and backend from the same host and port.
# To test with CORS locally, you can set something like
# CORS_ALLOW_ORIGIN='http://localhost:5173;http://localhost:8080'
CORS_ALLOW_ORIGIN='*'

# For production you should set this to match the proxy configuration (127.0.0.1)
FORWARDED_ALLOW_IPS='*'

# DO NOT TRACK
SCARF_NO_ANALYTICS=true
DO_NOT_TRACK=true
ANONYMIZED_TELEMETRY=false

# WebUI Configuration
WEBUI_SECRET_KEY=
WEBUI_JWT_SECRET_KEY=

# Port Configuration
OPEN_WEBUI_PORT=3000
PORT=8080
HOST=0.0.0.0

# Workers
UVICORN_WORKERS=1

# Docker Configuration
WEBUI_DOCKER_TAG=main