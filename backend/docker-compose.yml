# docker-compose.yml
services:
  ollama-ai:
    build:
      context: ./ollama_backend
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./ollama_backend:/ollama_backend:z
    environment:
      - OLLAMA_MODELS=${OLLAMA_MODELS}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s
volumes:
  ollama_data:
