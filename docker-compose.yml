# docker-compose.yml
services:
  ollama:
    build:
      context: ./backend/ollama_backend
      dockerfile: Dockerfile
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./backend/ollama_backend:/ollama_backend:ro
    environment:
      - OLLAMA_MODELS=${OLLAMA_MODELS}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s

  open-webui:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        OLLAMA_BASE_URL: '/ollama'
    image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG-main}
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - ${OPEN_WEBUI_PORT-3000}:8080
    environment:
      - 'OLLAMA_BASE_URL=http://ollama:11434'
      - 'WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY:-}'
      - 'CORS_ALLOW_ORIGIN=${CORS_ALLOW_ORIGIN:-*}'
      - 'FORWARDED_ALLOW_IPS=${FORWARDED_ALLOW_IPS:-*}'
      - 'SCARF_NO_ANALYTICS=${SCARF_NO_ANALYTICS:-true}'
      - 'DO_NOT_TRACK=${DO_NOT_TRACK:-true}'
      - 'ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-false}'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

volumes:
  ollama_data: {}
  open-webui: {}
